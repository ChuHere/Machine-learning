{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Mnist\n",
    "This project was made as a university assignment.\n",
    "\n",
    "We have 32x32 images in grayscale, they were made from Fashion Mnist dataset. The task is to classify images into specified labels. Training data is in train.csv. We will experiment with feedforward neural networks (FNNs) and convolutional neural networks (CNNs).\n",
    "\n",
    "There are several labels:\n",
    "* 0 - T-shirt/top\n",
    "* 1 - Trouser\n",
    "* 2 - Pullover\n",
    "* 3 - Dress\n",
    "* 4 - Coat\n",
    "* 5 - Sandal\n",
    "* 6 - Shirt\n",
    "* 7 - Sneaker\n",
    "* 8 - Bag\n",
    "* 9 - Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data\n",
    "def reshape_data(data):\n",
    "    tmp = data.reshape(-1, 1, 32, 32)\n",
    "    return tmp\n",
    "\n",
    "#Scale dataset\n",
    "def scale_one(scaler, train, target_data):\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    res = scaler.transform(target_data)\n",
    "    return reshape_data(res)\n",
    "\n",
    "#Scale train, val and test sets\n",
    "def scale_data(scaler, train, val, test):\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    val_scaled = scaler.transform(val)\n",
    "    test_scaled = scaler.transform(test)\n",
    "\n",
    "    return reshape_data(train_scaled), reshape_data(val_scaled), reshape_data(test_scaled)\n",
    "\n",
    "#Create a tensor dataset\n",
    "def create_dataset(data, data_res):\n",
    "    tmp = torch.utils.data.TensorDataset(torch.tensor(data).to(\"cuda\"), torch.tensor(data_res.values).to(\"cuda\"))\n",
    "    return tmp\n",
    "\n",
    "#Create a dataloader for models\n",
    "def create_loader(data, batch_s, shuffle):\n",
    "    tmp = torch.utils.data.DataLoader(data, batch_size=batch_s, shuffle=shuffle)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset has 52500 rows and 1025 features.\n",
    "\n",
    "Features **pixel1**-**1024** represent pixels in the imaxe (from left to right, row by row). Pixel values range from 0 to 255, the higher the number, the darker the corresponding pixel.\n",
    "\n",
    "There are no missing values in the dataset.\n",
    "\n",
    "Training dataset will be divided into training (60%), validation (20%) and testing (20%) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "Xdata = df.copy()\n",
    "_ = Xdata.drop('label', axis=1, inplace=True)\n",
    "Ydata = df['label']\n",
    "\n",
    "rd_seed = 10 #Fixed seed\n",
    "train, test, train_res, test_res = train_test_split(Xdata, Ydata, test_size=0.4, random_state=rd_seed)\n",
    "val, test, val_res, test_res = train_test_split(test, test_res, test_size=0.5, random_state=rd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pix1</th>\n",
       "      <th>pix2</th>\n",
       "      <th>pix3</th>\n",
       "      <th>pix4</th>\n",
       "      <th>pix5</th>\n",
       "      <th>pix6</th>\n",
       "      <th>pix7</th>\n",
       "      <th>pix8</th>\n",
       "      <th>pix9</th>\n",
       "      <th>pix10</th>\n",
       "      <th>...</th>\n",
       "      <th>pix1016</th>\n",
       "      <th>pix1017</th>\n",
       "      <th>pix1018</th>\n",
       "      <th>pix1019</th>\n",
       "      <th>pix1020</th>\n",
       "      <th>pix1021</th>\n",
       "      <th>pix1022</th>\n",
       "      <th>pix1023</th>\n",
       "      <th>pix1024</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pix1  pix2  pix3  pix4  pix5  pix6  pix7  pix8  pix9  pix10  ...  pix1016  \\\n",
       "0     0     0     0     0     0     0     0     0     0      0  ...        0   \n",
       "1     1     1     1     1     1     1     1     1     1      1  ...        1   \n",
       "2     1     1     1     1     1     1     1     1     1      1  ...        1   \n",
       "3     0     0     0     0     0     0     0     0     0      0  ...        0   \n",
       "4     1     1     1     1     1     1     1     1     1      1  ...        1   \n",
       "\n",
       "   pix1017  pix1018  pix1019  pix1020  pix1021  pix1022  pix1023  pix1024  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        1        1        1        1        1        1        1        1   \n",
       "2        1        1        1        1        1        1        1        1   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        1        1        1        1        1        1        1        1   \n",
       "\n",
       "   label  \n",
       "0      3  \n",
       "1      3  \n",
       "2      7  \n",
       "3      9  \n",
       "4      5  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (52500, 1025)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52500 entries, 0 to 52499\n",
      "Columns: 1025 entries, pix1 to label\n",
      "dtypes: int64(1025)\n",
      "memory usage: 410.6 MB\n",
      "None\n",
      "\n",
      "Number of null values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \" + str(df.shape))\n",
    "print()\n",
    "print(df.info())\n",
    "print()\n",
    "print(\"Number of null values: \" + str(df.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average pixel value is 44.74 in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.74\n"
     ]
    }
   ],
   "source": [
    "print(round(train.mean().mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display few images from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_row, n_col = 3, 3\n",
    "fig, axes = plt.subplots(n_row, n_col, figsize=(1*n_col, 1*n_row))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(n_row*n_col):\n",
    "    img = train.iloc[i, :].values.reshape(32, 32)\n",
    "    axes[i].imshow(img, cmap='gray_r', interpolation='nearest')\n",
    "    axes[i].set_title('Label: ' + str(train_res.iloc[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply standardization and MinMax normalization. The data will be then transformed into a suitable form for our neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_stand, val_stand, test_stand = scale_data(scaler, train, val, test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_mm, val_mm, test_mm = scale_data(scaler, train, val, test)\n",
    "\n",
    "train_rs = reshape_data(train.to_numpy().copy())\n",
    "val_rs = reshape_data(val.to_numpy().copy())\n",
    "test_rs = reshape_data(test.to_numpy().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_dataset(train_rs, train_res)\n",
    "train_data_stand = create_dataset(train_stand, train_res)\n",
    "train_data_mm = create_dataset(train_mm, train_res)\n",
    "\n",
    "val_data = create_dataset(val_rs, val_res)\n",
    "val_data_stand = create_dataset(val_stand, val_res)\n",
    "val_data_mm = create_dataset(val_mm, val_res)\n",
    "\n",
    "test_data = create_dataset(test_rs, test_res)\n",
    "test_data_stand = create_dataset(test_stand, test_res)\n",
    "test_data_mm = create_dataset(test_mm, test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = create_loader(train_data, 32, True)\n",
    "validation_loader = create_loader(val_data, 128, False)\n",
    "test_loader = create_loader(test_data, 128, False)\n",
    "\n",
    "training_loader_stand = create_loader(train_data_stand, 32, True)\n",
    "validation_loader_stand = create_loader(val_data_stand, 128, False)\n",
    "test_loader_stand = create_loader(test_data_stand, 128, False)\n",
    "\n",
    "training_loader_mm = create_loader(train_data_mm, 32, True)\n",
    "validation_loader_mm = create_loader(val_data_mm, 128, False)\n",
    "test_loader_mm = create_loader(test_data_mm, 128, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get model accuracy on given dataset\n",
    "def get_acc(model, dataset, loader):\n",
    "    predictions = np.zeros(len(dataset))\n",
    "    y_data = np.zeros(len(dataset))\n",
    "    ii = 0\n",
    "\n",
    "    for vdata in loader:\n",
    "        vinputs, vlabels = vdata\n",
    "        with torch.no_grad():\n",
    "            voutputs = model(vinputs.to(torch.float32))\n",
    "        predictions[ii:(ii + vinputs.shape[0])] = voutputs.cpu().argmax(1).numpy()\n",
    "        y_data[ii:(ii + vinputs.shape[0])] = vlabels.cpu().numpy()\n",
    "        ii += vinputs.shape[0]\n",
    "    print(f\"Test accuracy: {accuracy_score(y_data, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train one epoch\n",
    "def train_one_epoch(model, loss_fn, optimizer, train_l):\n",
    "    running_cum_loss = 0.\n",
    "\n",
    "    for data in train_l:\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.to(torch.float32))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        last_mean_loss = loss.item()\n",
    "        running_cum_loss += last_mean_loss * inputs.shape[0]\n",
    "            \n",
    "    return running_cum_loss / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "def net_train(model_t, train_l, val_l, optimizer):\n",
    "    EPOCHS = 25\n",
    "    tmp_acc = 0\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    tmp_acc = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        model_t.train(True)\n",
    "        avg_loss = train_one_epoch(model_t, loss_fn, optimizer, train_l)\n",
    "        model_t.train(False)\n",
    "\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for vdata in val_l:\n",
    "            vinputs, vlabels = vdata\n",
    "            with torch.no_grad():\n",
    "                voutputs = model_t(vinputs.to(torch.float32))\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "\n",
    "        avg_vloss = running_cum_vloss / len(val_data)\n",
    "        vacc = vcorrect / len(val_data)\n",
    "\n",
    "        tmp_acc = vacc\n",
    "    \n",
    "    return tmp_acc.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop with early-stopping regularization (based on validation accuracy)\n",
    "def net_train_early_stopping(model_t, train_l, val_l, model_path, optimizer, save=False):\n",
    "    MAX_EPOCHS = 30\n",
    "    K_EPOCHS = 5\n",
    "\n",
    "    epochs = []\n",
    "    train_loss = []\n",
    "    best_val_acc = 0\n",
    "    validation_loss = []\n",
    "    epochs_from_best = 0\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        model_t.train(True)\n",
    "        avg_loss = train_one_epoch(model_t, loss_fn, optimizer, train_l)   \n",
    "        model_t.train(False)\n",
    "\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for vdata in val_l:\n",
    "            vinputs, vlabels = vdata\n",
    "            with torch.no_grad():\n",
    "                voutputs = model_t(vinputs.to(torch.float32))\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "\n",
    "        avg_vloss = running_cum_vloss / len(val_data)\n",
    "        vacc = vcorrect / len(val_data)\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        validation_loss.append(avg_vloss)\n",
    "        train_loss.append(avg_loss)\n",
    "\n",
    "        if vacc > best_val_acc:\n",
    "            best_val_acc = vacc\n",
    "            if save:\n",
    "                torch.save(model_t.state_dict(), model_path)\n",
    "            epochs_from_best = 0\n",
    "        else:\n",
    "            epochs_from_best += 1\n",
    "\n",
    "        if epochs_from_best > K_EPOCHS:\n",
    "            break\n",
    "\n",
    "    return best_val_acc.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try two types of neural networks: feedforward and convolutional.\n",
    "\n",
    "We will experiment with different layer depths/sizes, optimization and regularization methods. We will use standardization/normalization.\n",
    "\n",
    "Regularization: early-stopping (stopping training after k-epochs of no improvement), dropout(2d) (resetting random inputs/channels to layer)\n",
    "\n",
    "Optimization methods: Adam and SGD + different learning rates\n",
    "\n",
    "Several models were tried, but only the more important ones were left. The activation functions RELU and softmax (in the loss function) were used.\n",
    "\n",
    "Disclaimer: The training of neural networks does not always turn out the same (with the same model), the observations I made were made from the average of several attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedforward neural networks are generally not bad at image classification. Each neuron is connected to each neuron in the following layer, each pixel is taken as a separate feature, which can lead to high dimensionality of the inputs. This type does not capture much spatial information (like surrounding pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic model for layer number tuning, static layer size\n",
    "# class forward_net_gen(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, layers_num):\n",
    "#         super().__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "#         self.layers_num = layers_num\n",
    "\n",
    "#         self.layers = nn.ModuleList()\n",
    "\n",
    "#         self.layers.append(nn.Linear(input_size, hidden_size).to(\"cuda\"))\n",
    "#         for i in range(self.layers_num-2):\n",
    "#             self.layers.append(nn.Linear(hidden_size, hidden_size).to(\"cuda\"))\n",
    "#         self.layers.append(nn.Linear(hidden_size, output_size).to(\"cuda\"))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.flatten(start_dim = 1)\n",
    "#         for i in range(len(self.layers)-1):\n",
    "#             x = F.relu(self.layers[i](x))\n",
    "#         x = self.layers[-1](x)\n",
    "#         return x\n",
    "\n",
    "# One hidden layer (RELU) + output layer (softmax)\n",
    "class forward_net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 256).to(\"cuda\")\n",
    "        self.fco = nn.Linear(256, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Three hidden layers (RELU) + output layer (softmax)\n",
    "class forward_net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 32*32).to(\"cuda\")\n",
    "        self.fc2 = nn.Linear(32*32, 512).to(\"cuda\")\n",
    "        self.fc3 = nn.Linear(512, 128).to(\"cuda\")\n",
    "        self.fco = nn.Linear(128, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Three hidden layers (RELU), dropout (after 1st) + output layer (softmax)\n",
    "class forward_net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 32*32).to(\"cuda\")\n",
    "        self.fc1_drop = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(32*32, 256).to(\"cuda\")\n",
    "        self.fc3 = nn.Linear(256, 64).to(\"cuda\")\n",
    "        self.fco = nn.Linear(64, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Three hidden layers (RELU), dropout (after each) + output layer (softmax)\n",
    "class forward_net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 32*32).to(\"cuda\")\n",
    "        self.fc1_drop = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(32*32, 256).to(\"cuda\")\n",
    "        self.fc2_drop = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(256, 64).to(\"cuda\")\n",
    "        self.fc3_drop = nn.Dropout(0.1)\n",
    "        self.fco = nn.Linear(64, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc3_drop(x)\n",
    "        x = self.fco(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for the generic model\n",
    "\n",
    "# forward_net_grid = {\n",
    "#     'input_size': [32*32],\n",
    "#     'hidden_size': [16, 20, 24],\n",
    "#     'output_size': [10, 14, 18],\n",
    "#     'layers_num': [*range(4, 7)]\n",
    "# }\n",
    "\n",
    "# forward_net_param = ParameterGrid(forward_net_grid)\n",
    "\n",
    "# val_acc = []\n",
    "\n",
    "# with tqdm(total=len(forward_net_param)) as pbar:\n",
    "#     for x in forward_net_param:\n",
    "#         print(x)\n",
    "#         tmp_model = forward_net(x['input_size'], x['hidden_size'], x['output_size'], x['layers_num']).to(\"cuda\")\n",
    "#         val_acc.append(forward_net_train(tmp_model, training_loader, validation_loader))\n",
    "#         pbar.update(1)\n",
    "\n",
    "# best_m = forward_net_param[np.argmax(val_acc)]\n",
    "\n",
    "# vanilla = forward_net(best_m['input_size'], best_m['hidden_size'], best_m['output_size'], best_m['layers_num']).to(\"cuda\")\n",
    "# print(forward_net_train(vanilla, training_loader, validation_loader))\n",
    "# torch.save(vanilla.state_dict(), \"forwardNN/vanilla.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Adam optimizer for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val): 0.79029\n",
      "Accuracy score (val) - early stopping: 0.78990\n"
     ]
    }
   ],
   "source": [
    "ffnn_1 = forward_net1()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_1.parameters())\n",
    "print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_1, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_1, training_loader, validation_loader, 'forwardNN/tmp.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val): 0.82429\n",
      "Accuracy score (val) - early stopping: 0.84638\n"
     ]
    }
   ],
   "source": [
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_2.parameters())\n",
    "print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_2, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader, validation_loader, 'forwardNN/ffnn_2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val): 0.83914\n",
      "Accuracy score (val) - early stopping: 0.84876\n"
     ]
    }
   ],
   "source": [
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_3.parameters())\n",
    "print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_3, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader, validation_loader, 'forwardNN/ffnn_3.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val): 0.83381\n",
      "Accuracy score (val) - early stopping: 0.84286\n"
     ]
    }
   ],
   "source": [
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_4.parameters())\n",
    "print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_4, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader, validation_loader, 'forwardNN/ffnn_4.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that early-stopping regularization improves the models.\n",
    "\n",
    "The basic model (1.) had the worst accuracy. More complex models performed better and have decent results. The best model is the 3rd with accuracy of 85% (dropout after the 1st layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left models with early-stopping in the notebook, it gave better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.84600\n"
     ]
    }
   ],
   "source": [
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_2, training_loader_stand, validation_loader_stand, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_stand, validation_loader_stand, 'forwardNN/ffnn_2_stand.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.84771\n"
     ]
    }
   ],
   "source": [
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_3.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_3, training_loader_stand, validation_loader_stand, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_stand, validation_loader_stand, 'forwardNN/ffnn_3_stand.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.85143\n"
     ]
    }
   ],
   "source": [
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_4.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_4, training_loader_stand, validation_loader_stand, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_stand, validation_loader_stand, 'forwardNN/ffnn_4_stand.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization improves the models slightly on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left models with early-stopping in the notebook, it gave better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.85533\n"
     ]
    }
   ],
   "source": [
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_2, training_loader_mm, validation_loader_mm, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_2_mm.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.85210\n"
     ]
    }
   ],
   "source": [
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_3.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_3, training_loader_mm, validation_loader_mm, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_3_mm.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.85524\n"
     ]
    }
   ],
   "source": [
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_4.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(ffnn_4, training_loader_mm, validation_loader_mm, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_4_mm.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization improves models on average (more than standardization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimalization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left models with early-stopping in the notebook, it gave better results. We will use normalization here since it improved our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizer (lr=0.005):\n",
      "Accuracy score (val) - early stopping: 0.84067\n",
      "\n",
      "Adam optimizer (lr=0.003):\n",
      "Accuracy score (val) - early stopping: 0.84600\n"
     ]
    }
   ],
   "source": [
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_2.parameters(), lr=0.005)\n",
    "print(\"Adam optimizer (lr=0.005):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_2_mm_a1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_2.parameters(), lr=0.003)\n",
    "print(\"Adam optimizer (lr=0.003):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_2_mm_a2.pt', optimizer_tmp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer:\n",
      "Accuracy score (val) - early stopping: 0.71371\n"
     ]
    }
   ],
   "source": [
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_2.parameters())\n",
    "print(\"SGD optimizer:\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_2_mm_sgd.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.83838\n",
      "\n",
      "SGD optimizer (lr=0.03):\n",
      "Accuracy score (val) - early stopping: 0.83886\n"
     ]
    }
   ],
   "source": [
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_2.parameters(), lr=0.01)\n",
    "print(\"SGD optimizer (lr=0.01):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_2_mm_sgd1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "ffnn_2 = forward_net2()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_2.parameters(), lr=0.03)\n",
    "print(\"SGD optimizer (lr=0.03):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_2, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_2_mm_sgd2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizer (lr=0.005):\n",
      "Accuracy score (val) - early stopping: 0.83438\n",
      "\n",
      "Adam optimizer (lr=0.003):\n",
      "Accuracy score (val) - early stopping: 0.85095\n"
     ]
    }
   ],
   "source": [
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_3.parameters(), lr=0.005)\n",
    "print(\"Adam optimizer (lr=0.005):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_3_mm_a1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_3.parameters(), lr=0.003)\n",
    "print(\"Adam optimizer (lr=0.003):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_3_mm_a2.pt', optimizer_tmp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer:\n",
      "Accuracy score (val) - early stopping: 0.83686\n"
     ]
    }
   ],
   "source": [
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_3.parameters())\n",
    "print(\"SGD optimizer:\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_3_mm_sgd.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.84514\n",
      "\n",
      "SGD optimizer (lr=0.03):\n",
      "Accuracy score (val) - early stopping: 0.85467\n"
     ]
    }
   ],
   "source": [
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_3.parameters(), lr=0.01)\n",
    "print(\"SGD optimizer (lr=0.01):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_3_mm_sgd1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "ffnn_3 = forward_net3()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_3.parameters(), lr=0.03)\n",
    "print(\"SGD optimizer (lr=0.03):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_3, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_3_mm_sgd2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizer (lr=0.005):\n",
      "Accuracy score (val) - early stopping: 0.82333\n",
      "\n",
      "Adam optimizer (lr=0.003):\n",
      "Accuracy score (val) - early stopping: 0.85190\n"
     ]
    }
   ],
   "source": [
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_4.parameters(), lr=0.005)\n",
    "print(\"Adam optimizer (lr=0.005):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_4_mm_a1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.Adam(ffnn_4.parameters(), lr=0.003)\n",
    "print(\"Adam optimizer (lr=0.003):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_4_mm_a2.pt', optimizer_tmp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.83800\n"
     ]
    }
   ],
   "source": [
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_4.parameters())\n",
    "print(\"SGD optimizer:\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_4_mm_sgd.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.84343\n",
      "\n",
      "SGD optimizer (lr=0.03):\n",
      "Accuracy score (val) - early stopping: 0.84743\n"
     ]
    }
   ],
   "source": [
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_4.parameters(), lr=0.01)\n",
    "print(\"SGD optimizer (lr=0.01):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_4_mm_sgd1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "ffnn_4 = forward_net4()\n",
    "optimizer_tmp = torch.optim.SGD(ffnn_4.parameters(), lr=0.03)\n",
    "print(\"SGD optimizer (lr=0.03):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(ffnn_4, training_loader_mm, validation_loader_mm, 'forwardNN/ffnn_4_mm_sgd2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the learning rate (Adam optimizer) did not significantly help the models, the default setting (0.001) performed best. SGD also did not improve the models on average, generally performing slightly worse than Adam after learning rate tuning (0.03)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks are very popular in image classification. Using convolution they can capture a pattern in images and it reduces complexity. Therefore, they capture better spatial information (e.g. the relationship of surrounding pixels). This type is more suitable than feedforward networks for this type of task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPool2d - extracts the highest values â€‹â€‹in the region\n",
    "\n",
    "# Two convolutional layers (RELU and MaxPool) + output layer (softmax)\n",
    "class conv_net2_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 40, kernel_size = 3).to(\"cuda\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(40, 16, 3).to(\"cuda\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fco = nn.Linear(16*6*6, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Two convolutional layers (RELU and MaxPool), dropout2d (after each) + two hidden layers (RELU), dropout (after 1st) + output layer (softmax)\n",
    "class conv_net2_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3).to(\"cuda\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv1_drop = nn.Dropout2d(p=0.2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3).to(\"cuda\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2_drop = nn.Dropout2d(p=0.2)\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600).to(\"cuda\")\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=128).to(\"cuda\")\n",
    "        self.fco = nn.Linear(128, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv1_drop(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Two convolutional layers (RELU and MaxPool) + two hidden layers (RELU), dropout (after 1st) + output layer (softmax)\n",
    "class conv_net2_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3).to(\"cuda\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3).to(\"cuda\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600).to(\"cuda\")\n",
    "        self.fc1_drop = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=128).to(\"cuda\")\n",
    "        self.fco = nn.Linear(128, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Three convolutional layers (RELU and MaxPool) + output layer (softmax)\n",
    "class conv_net3_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3).to(\"cuda\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3).to(\"cuda\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3).to(\"cuda\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc1 = nn.Linear(64*2*2, 128).to(\"cuda\")\n",
    "        self.fco = nn.Linear(128, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Three convolutional layers (RELU and MaxPool), dropout2d (after each) + one hidden layer (RELU) + output layer (softmax)\n",
    "class conv_net3_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3).to(\"cuda\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv1_drop = nn.Dropout2d(p=0.2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3).to(\"cuda\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2_drop = nn.Dropout2d(p=0.2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3).to(\"cuda\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv3_drop = nn.Dropout2d(p=0.2)\n",
    "        self.fc1 = nn.Linear(64*2*2, 128).to(\"cuda\")\n",
    "        self.fco = nn.Linear(128, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv1_drop(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv3_drop(x)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "# Three convolutional layers (RELU and MaxPool), dropout2d (after each) + one hidden layer (RELU), dropout + output layer (softmax)\n",
    "class conv_net3_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3).to(\"cuda\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv1_drop = nn.Dropout2d(p=0.2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3).to(\"cuda\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2_drop = nn.Dropout2d(p=0.2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3).to(\"cuda\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv3_drop = nn.Dropout2d(p=0.2)\n",
    "        self.fc1 = nn.Linear(64*2*2, 128).to(\"cuda\")\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.fco = nn.Linear(128, 10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv1_drop(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv3_drop(x)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = self.fco(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, models with early-stopping regularization performed better, leaving models with early-stopping in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val): 0.84676\n",
      "Accuracy score (val) - early stopping: 0.84686\n"
     ]
    }
   ],
   "source": [
    "cvn2_1 = conv_net2_1()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_1.parameters())\n",
    "print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_1, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_1, training_loader, validation_loader, 'conv_models/cvn2_1.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val): 0.88200\n",
      "Accuracy score (val) - early stopping: 0.88571\n"
     ]
    }
   ],
   "source": [
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_2.parameters())\n",
    "print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_2, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader, validation_loader, 'conv_models/cvn2_2.pt', optimizer_tmp, True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.88105\n"
     ]
    }
   ],
   "source": [
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_3.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_3, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader, validation_loader, 'conv_models/cvn2_3.pt', optimizer_tmp, True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.87410\n"
     ]
    }
   ],
   "source": [
    "cvn3_1 = conv_net3_1()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_1.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn3_1, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_1, training_loader, validation_loader, 'conv_models/cvn3_1.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.87629\n"
     ]
    }
   ],
   "source": [
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn3_2, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader, validation_loader, 'conv_models/cnv3_2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.87352\n"
     ]
    }
   ],
   "source": [
    "cvn3_3 = conv_net3_3()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_3.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn3_2, training_loader, validation_loader, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_3, training_loader, validation_loader, 'conv_models/cvn3_3.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first basic model performed the worst. More complex models performed noticeably better and had good results. The best model was generally cvn2_2 (i.e. 2 convolutional layers with dropout and 2 hidden layers with dropout after 1st)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue with only selected models that generally performed the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.89467\n"
     ]
    }
   ],
   "source": [
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_2, training_loader_stand, validation_loader_stand, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_stand, validation_loader_stand, 'conv_models/cvn2_2_stand.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.88895\n"
     ]
    }
   ],
   "source": [
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_3.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_3, training_loader_stand, validation_loader_stand, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_stand, validation_loader_stand, 'conv_models/cvn2_3_stand.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.88819\n"
     ]
    }
   ],
   "source": [
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn3_2, training_loader_stand, validation_loader_stand, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_stand, validation_loader_stand, 'conv_models/cnv3_2_stand.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization slightly improved our models on average. We are hovering around 89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.89552\n"
     ]
    }
   ],
   "source": [
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_2, training_loader_mm, validation_loader_mm, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_2_mm.pt', optimizer_tmp, True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.89724\n"
     ]
    }
   ],
   "source": [
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_3.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn2_3, training_loader_mm, validation_loader_mm, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_3_mm.pt', optimizer_tmp, True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (val) - early stopping: 0.89429\n"
     ]
    }
   ],
   "source": [
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_2.parameters())\n",
    "# print('Accuracy score (val): {0:.5f}'.format(net_train(cvn3_2, training_loader_mm, validation_loader_mm, optimizer_tmp)))\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_mm, validation_loader_mm, 'conv_models/cnv3_2_mm.pt', optimizer_tmp, True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here too, normalization improves the models on average (more than standardization). We are hovering around 89%.\n",
    "\n",
    "Cvn2_3 (2 convolutional layers and 2 hidden with dropout after 1) achieved a very good 90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimalization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left models with early-stopping in the notebook, it gave better results. We will also use normalization here, as it improved our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizer (lr=0.005):\n",
      "Accuracy score (val) - early stopping: 0.87076\n",
      "\n",
      "Adam optimizer (lr=0.003):\n",
      "Accuracy score (val) - early stopping: 0.88771\n"
     ]
    }
   ],
   "source": [
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_2.parameters(), lr=0.005)\n",
    "print(\"Adam optimizer (lr=0.005):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_2_mm_a1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_2.parameters(), lr=0.003)\n",
    "print(\"Adam optimizer (lr=0.003):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_2_mm_a1.pt', optimizer_tmp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer:\n",
      "Accuracy score (val) - early stopping: 0.75248\n",
      "\n",
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.87000\n",
      "\n",
      "SGD optimizer (lr=0.03):\n",
      "Accuracy score (val) - early stopping: 0.88590\n"
     ]
    }
   ],
   "source": [
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.SGD(cvn2_2.parameters())\n",
    "print(\"SGD optimizer:\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_2_mm_sgd.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.SGD(cvn2_2.parameters(), lr=0.01)\n",
    "print(\"SGD optimizer (lr=0.01):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_2_mm_sgd1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn2_2 = conv_net2_2()\n",
    "optimizer_tmp = torch.optim.SGD(cvn2_2.parameters(), lr=0.03)\n",
    "print(\"SGD optimizer (lr=0.03):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_2_mm_sgd2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizer (lr=0.005):\n",
      "Accuracy score (val) - early stopping: 0.87876\n",
      "\n",
      "Adam optimizer (lr=0.003):\n",
      "Accuracy score (val) - early stopping: 0.88952\n"
     ]
    }
   ],
   "source": [
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_3.parameters(), lr=0.005)\n",
    "print(\"Adam optimizer (lr=0.005):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_3_mm_a1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.Adam(cvn2_3.parameters(), lr=0.003)\n",
    "print(\"Adam optimizer (lr=0.003):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_3_mm_a2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer:\n",
      "Accuracy score (val) - early stopping: 0.77076\n",
      "\n",
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.87057\n",
      "\n",
      "SGD optimizer (lr=0.03):\n",
      "Accuracy score (val) - early stopping: 0.89305\n"
     ]
    }
   ],
   "source": [
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.SGD(cvn2_3.parameters())\n",
    "print(\"SGD optimizer:\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_3_mm_sgd.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.SGD(cvn2_3.parameters(), lr=0.01)\n",
    "print(\"SGD optimizer (lr=0.01):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_3_mm_sgd1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn2_3 = conv_net2_3()\n",
    "optimizer_tmp = torch.optim.SGD(cvn2_3.parameters(), lr=0.03)\n",
    "print(\"SGD optimizer (lr=0.03):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn2_3, training_loader_mm, validation_loader_mm, 'conv_models/cvn2_3_mm_sgd2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizer (lr=0.005):\n",
      "Accuracy score (val) - early stopping: 0.85781\n",
      "\n",
      "Adam optimizer (lr=0.003):\n",
      "Accuracy score (val) - early stopping: 0.87886\n"
     ]
    }
   ],
   "source": [
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_2.parameters(), lr=0.005)\n",
    "print(\"Adam optimizer (lr=0.005):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn3_2_mm_a1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.Adam(cvn3_2.parameters(), lr=0.003)\n",
    "print(\"Adam optimizer (lr=0.003):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn3_2_mm_a2.pt', optimizer_tmp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer:\n",
      "Accuracy score (val) - early stopping: 0.73210\n",
      "\n",
      "SGD optimizer (lr=0.01):\n",
      "Accuracy score (val) - early stopping: 0.84067\n",
      "\n",
      "SGD optimizer (lr=0.03):\n",
      "Accuracy score (val) - early stopping: 0.87819\n"
     ]
    }
   ],
   "source": [
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.SGD(cvn3_2.parameters())\n",
    "print(\"SGD optimizer:\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn3_2_mm_sgd.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.SGD(cvn3_2.parameters(), lr=0.01)\n",
    "print(\"SGD optimizer (lr=0.01):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn3_2_mm_sgd1.pt', optimizer_tmp)))\n",
    "print('')\n",
    "cvn3_2 = conv_net3_2()\n",
    "optimizer_tmp = torch.optim.SGD(cvn3_2.parameters(), lr=0.03)\n",
    "print(\"SGD optimizer (lr=0.03):\")\n",
    "print('Accuracy score (val) - early stopping: {0:.5f}'.format(net_train_early_stopping(cvn3_2, training_loader_mm, validation_loader_mm, 'conv_models/cvn3_2_mm_sgd2.pt', optimizer_tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not notice an improvement of the models when tuning the learning rate of the Adam optimizer (compared to the default 0.001). SGD performed worse than Adam even when tuning the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs performed significantly better than FNNs. Normalization/standardization helped the models (mainly normalization). For optimization methods, Adam performed best with default settings. Regularization (early-stopping and dropout) helped the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the final model, we choose the model that generally performed the best, which is the cvn2_3 CNN with MinMax normalization, early-stopping and the default Adam optimizer.\n",
    "\n",
    "Cvn2_3: two convolutional layers (RELU and MaxPool) + two hidden layers (RELU), dropout (after 1st) + output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = conv_net2_3()\n",
    "final_model.load_state_dict(torch.load('conv_models/cvn2_3_mm.pt'))\n",
    "_ = final_model.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected accuracy of this model on new data is around 89.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.892\n"
     ]
    }
   ],
   "source": [
    "get_acc(final_model, test_data_mm, test_loader_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
